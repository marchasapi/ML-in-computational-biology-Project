{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "import sys\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED=42\n",
    "SOURCE_FILE = \"../data_preprocessed/everything40_cleaned_normalized_reduced.csv\"\n",
    "VERBOSE = True\n",
    "\n",
    "APPLY_SAMPLE_CUT_OFF = False\n",
    "LIMIT_SAMPLES = 50 # sample cells\n",
    "LIMIT_FEATURES = 500 # sample genes\n",
    "\n",
    "np.random.seed(42) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 141 ms\n",
      "Wall time: 189 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dataset = pd.read_csv(SOURCE_FILE,index_col = 0)\n",
    "\n",
    "if APPLY_SAMPLE_CUT_OFF:\n",
    "    print(\"Applying cut off: \", LIMIT_SAMPLES, LIMIT_FEATURES)\n",
    "    print(\"Before cut off: \", dataset.shape)\n",
    "    dataset = dataset.iloc[0:LIMIT_SAMPLES, dataset.shape[1]-LIMIT_FEATURES:]\n",
    "    print(\"After cut off: \", dataset.shape)\n",
    "\n",
    "genes = dataset.shape[1] - 1\n",
    "labels_count = dataset['Classification'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples:  4679\n",
      "Total genes  :  138\n",
      "Total classes:  75\n"
     ]
    }
   ],
   "source": [
    "print(\"Total samples: \", dataset.shape[0])\n",
    "print(\"Total genes  : \", dataset.shape[1] - 1)\n",
    "print(\"Total classes: \", labels_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4679, 138)\n",
      "(4679,)\n"
     ]
    }
   ],
   "source": [
    "X = dataset.iloc[:, :-1]\n",
    "Y = dataset.iloc[:, -1]\n",
    "\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Astro L1-2 FGFR3 GFAP', 'Astro L1-6 FGFR3 SLC14A1',\n",
       "       'Endo L2-6 NOSTRIN', 'Exc L2 LAMP5 LTK',\n",
       "       'Exc L2-3 LINC00507 FREM3', 'Exc L2-4 LINC00507 GLP2R',\n",
       "       'Exc L3-4 RORB CARM1P1', 'Exc L3-5 RORB COL22A1',\n",
       "       'Exc L3-5 RORB ESR1', 'Exc L3-5 RORB FILIP1L',\n",
       "       'Exc L3-5 RORB TWIST2', 'Exc L4-5 FEZF2 SCN4B',\n",
       "       'Exc L4-5 RORB DAPK2', 'Exc L4-5 RORB FOLH1B',\n",
       "       'Exc L4-6 FEZF2 IL26', 'Exc L4-6 RORB C1R', 'Exc L4-6 RORB SEMA3E',\n",
       "       'Exc L5-6 FEZF2 ABO', 'Exc L5-6 FEZF2 EFTUD1P1',\n",
       "       'Exc L5-6 RORB TTC12', 'Exc L5-6 SLC17A7 IL15',\n",
       "       'Exc L5-6 THEMIS C1QL3', 'Exc L5-6 THEMIS CRABP1',\n",
       "       'Exc L5-6 THEMIS DCSTAMP', 'Exc L5-6 THEMIS FGF10',\n",
       "       'Exc L6 FEZF2 OR2T8', 'Exc L6 FEZF2 SCUBE1', 'Inh L1 SST CHRNA4',\n",
       "       'Inh L1 SST NMBR', 'Inh L1-2 GAD1 MC4R', 'Inh L1-2 LAMP5 DBP',\n",
       "       'Inh L1-2 PAX6 CDH12', 'Inh L1-2 PAX6 TNFAIP8L3',\n",
       "       'Inh L1-2 SST BAGE2', 'Inh L1-2 VIP LBH', 'Inh L1-2 VIP PCDH20',\n",
       "       'Inh L1-2 VIP TSPAN12', 'Inh L1-3 PAX6 SYT6', 'Inh L1-3 SST CALB1',\n",
       "       'Inh L1-3 VIP ADAMTSL1', 'Inh L1-3 VIP CCDC184',\n",
       "       'Inh L1-3 VIP CHRM2', 'Inh L1-3 VIP GGH', 'Inh L1-4 LAMP5 LCP2',\n",
       "       'Inh L1-4 VIP CHRNA6', 'Inh L1-4 VIP OPRM1', 'Inh L1-4 VIP PENK',\n",
       "       'Inh L2-3 VIP CASC6', 'Inh L2-4 PVALB WFDC2', 'Inh L2-4 SST FRZB',\n",
       "       'Inh L2-4 VIP CBLN1', 'Inh L2-4 VIP SPAG17',\n",
       "       'Inh L2-5 PVALB SCUBE3', 'Inh L2-5 VIP SERPINF1',\n",
       "       'Inh L2-5 VIP TYR', 'Inh L2-6 LAMP5 CA1', 'Inh L2-6 VIP QPCT',\n",
       "       'Inh L3-5 SST ADGRG6', 'Inh L3-6 SST HPGD', 'Inh L3-6 SST NPY',\n",
       "       'Inh L3-6 VIP HS3ST3A1', 'Inh L4-5 PVALB MEPE',\n",
       "       'Inh L4-5 SST STK32A', 'Inh L4-6 PVALB SULF1',\n",
       "       'Inh L4-6 SST B3GAT2', 'Inh L4-6 SST GXYLT2',\n",
       "       'Inh L5-6 GAD1 GLP1R', 'Inh L5-6 PVALB LGR5',\n",
       "       'Inh L5-6 SST KLHDC8A', 'Inh L5-6 SST MIR548F2',\n",
       "       'Inh L5-6 SST NPM1P10', 'Inh L5-6 SST TH', 'Micro L1-3 TYROBP',\n",
       "       'OPC L1-6 PDGFRA', 'Oligo L1-6 OPALIN'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(Y) # labels to indices\n",
    "y_categorical = to_categorical(y_encoded, num_classes=labels_count) # indices to 1 hot vectors\n",
    "label_encoder.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create test, train splits datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, y_categorical, test_size=0.2, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset:  4679 cells with 138 genes per cell\n",
      "Training   with :  3743 cells with 138 genes per cell\n",
      "Validating with :  936 cells with 138 genes per cell\n"
     ]
    }
   ],
   "source": [
    "print(\"Original dataset: \", X.shape[0],\"cells with\", X.shape[1], \"genes per cell\")\n",
    "print(\"Training   with : \", x_train.shape[0],\"cells with\", x_train.shape[1], \"genes per cell\")\n",
    "print(\"Validating with : \", x_test.shape[0],\"cells with\", x_test.shape[1], \"genes per cell\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateNeuralNetwork(genes, classes, layers, neurons_per_layer, drop_out = 0.2, activ = \"relu\", learning_rate=0.001, verbose = False):\n",
    "    model = tf.keras.Sequential()   \n",
    "\n",
    "    model.add(Input(shape=(genes,))) \n",
    "\n",
    "    for i in range(layers):\n",
    "        model.add(Dense(neurons_per_layer, activation = activ))\n",
    "        model.add(Dropout(drop_out))\n",
    "\n",
    "    model.add(Dense(classes, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=learning_rate), metrics=[\"accuracy\"])\n",
    "\n",
    "    if verbose:\n",
    "        print(model.summary())\n",
    "\n",
    "    return model\n",
    "\n",
    "# epochs = 100\n",
    "# model = CreateNeuralNetwork(genes, labels_count, 3, 100, 0.2)\n",
    "# callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=0)\n",
    "# history = model.fit(x_train, y_train, epochs=epochs, validation_data=(x_test, y_test), callbacks=callback)\n",
    "# train_accuracy = history.history['accuracy'][-1]\n",
    "# val_accuracy = history.history['val_accuracy'][-1]\n",
    "# print(train_accuracy)\n",
    "# print(val_accuracy)\n",
    "# best_model = model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examining case:  0 3 100 0.1 relu 0.0001\n",
      "Epoch 1/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0618 - loss: 5.5085 - val_accuracy: 0.2521 - val_loss: 3.4299\n",
      "Epoch 2/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2370 - loss: 3.5604 - val_accuracy: 0.4850 - val_loss: 2.5424\n",
      "Epoch 3/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4087 - loss: 2.7594 - val_accuracy: 0.5876 - val_loss: 2.0222\n",
      "Epoch 4/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5150 - loss: 2.2525 - val_accuracy: 0.6538 - val_loss: 1.6534\n",
      "Epoch 5/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5781 - loss: 1.9142 - val_accuracy: 0.6880 - val_loss: 1.4055\n",
      "Epoch 6/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6240 - loss: 1.6548 - val_accuracy: 0.7276 - val_loss: 1.2157\n",
      "Epoch 7/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6672 - loss: 1.4348 - val_accuracy: 0.7511 - val_loss: 1.0688\n",
      "Epoch 8/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6984 - loss: 1.2549 - val_accuracy: 0.7714 - val_loss: 0.9500\n",
      "Epoch 9/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7211 - loss: 1.1604 - val_accuracy: 0.7874 - val_loss: 0.8534\n",
      "Epoch 10/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7478 - loss: 0.9972 - val_accuracy: 0.7927 - val_loss: 0.7699\n",
      "Epoch 11/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7632 - loss: 0.9025 - val_accuracy: 0.8002 - val_loss: 0.6981\n",
      "Epoch 12/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7699 - loss: 0.8375 - val_accuracy: 0.8120 - val_loss: 0.6392\n",
      "Epoch 13/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8092 - loss: 0.7213 - val_accuracy: 0.8248 - val_loss: 0.5849\n",
      "Epoch 14/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8108 - loss: 0.7058 - val_accuracy: 0.8301 - val_loss: 0.5458\n",
      "Epoch 15/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8196 - loss: 0.6520 - val_accuracy: 0.8462 - val_loss: 0.5070\n",
      "Epoch 16/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8262 - loss: 0.6225 - val_accuracy: 0.8494 - val_loss: 0.4735\n",
      "Epoch 17/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8392 - loss: 0.5728 - val_accuracy: 0.8568 - val_loss: 0.4461\n",
      "Epoch 18/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8484 - loss: 0.5155 - val_accuracy: 0.8590 - val_loss: 0.4198\n",
      "Epoch 19/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8554 - loss: 0.4953 - val_accuracy: 0.8707 - val_loss: 0.4005\n",
      "Epoch 20/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8524 - loss: 0.4696 - val_accuracy: 0.8729 - val_loss: 0.3823\n",
      "Epoch 21/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8539 - loss: 0.4583 - val_accuracy: 0.8697 - val_loss: 0.3734\n",
      "Epoch 22/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8404 - loss: 0.4928 - val_accuracy: 0.8739 - val_loss: 0.3600\n",
      "Epoch 23/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8681 - loss: 0.3987 - val_accuracy: 0.8750 - val_loss: 0.3502\n",
      "Epoch 24/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8859 - loss: 0.3858 - val_accuracy: 0.8803 - val_loss: 0.3369\n",
      "Epoch 25/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8823 - loss: 0.3738 - val_accuracy: 0.8803 - val_loss: 0.3287\n",
      "Epoch 26/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8852 - loss: 0.3563 - val_accuracy: 0.8868 - val_loss: 0.3188\n",
      "Epoch 27/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8987 - loss: 0.3229 - val_accuracy: 0.8889 - val_loss: 0.3119\n",
      "Epoch 28/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8913 - loss: 0.3258 - val_accuracy: 0.8878 - val_loss: 0.3081\n",
      "Epoch 29/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8957 - loss: 0.3128 - val_accuracy: 0.8889 - val_loss: 0.3052\n",
      "Epoch 30/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9069 - loss: 0.2833 - val_accuracy: 0.8942 - val_loss: 0.2952\n",
      "Epoch 31/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9116 - loss: 0.2689 - val_accuracy: 0.8942 - val_loss: 0.2910\n",
      "Epoch 32/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9138 - loss: 0.2666 - val_accuracy: 0.8900 - val_loss: 0.2889\n",
      "Epoch 33/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9059 - loss: 0.2720 - val_accuracy: 0.8942 - val_loss: 0.2790\n",
      "Epoch 34/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9156 - loss: 0.2473 - val_accuracy: 0.8964 - val_loss: 0.2752\n",
      "Epoch 35/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9230 - loss: 0.2309 - val_accuracy: 0.8900 - val_loss: 0.2744\n",
      "Epoch 36/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9224 - loss: 0.2315 - val_accuracy: 0.8964 - val_loss: 0.2730\n",
      "Epoch 37/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9212 - loss: 0.2363 - val_accuracy: 0.8932 - val_loss: 0.2726\n",
      "Epoch 38/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9273 - loss: 0.2136 - val_accuracy: 0.8964 - val_loss: 0.2659\n",
      "Epoch 39/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9386 - loss: 0.1985 - val_accuracy: 0.9028 - val_loss: 0.2677\n",
      "Epoch 40/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9271 - loss: 0.2071 - val_accuracy: 0.9028 - val_loss: 0.2652\n",
      "Epoch 41/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9444 - loss: 0.1758 - val_accuracy: 0.9006 - val_loss: 0.2662\n",
      "Epoch 42/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9414 - loss: 0.1859 - val_accuracy: 0.9017 - val_loss: 0.2576\n",
      "Epoch 43/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9434 - loss: 0.1750 - val_accuracy: 0.9071 - val_loss: 0.2536\n",
      "Epoch 44/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9462 - loss: 0.1680 - val_accuracy: 0.9049 - val_loss: 0.2574\n",
      "Epoch 45/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9448 - loss: 0.1597 - val_accuracy: 0.9060 - val_loss: 0.2540\n",
      "Epoch 46/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9414 - loss: 0.1739 - val_accuracy: 0.9071 - val_loss: 0.2568\n",
      "Epoch 47/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9516 - loss: 0.1541 - val_accuracy: 0.9038 - val_loss: 0.2551\n",
      "Epoch 48/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9459 - loss: 0.1491 - val_accuracy: 0.9092 - val_loss: 0.2519\n",
      "Epoch 49/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9492 - loss: 0.1586 - val_accuracy: 0.9049 - val_loss: 0.2542\n",
      "Epoch 50/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9398 - loss: 0.1608 - val_accuracy: 0.9071 - val_loss: 0.2540\n",
      "Epoch 51/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9450 - loss: 0.1457 - val_accuracy: 0.9060 - val_loss: 0.2504\n",
      "Epoch 52/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9513 - loss: 0.1354 - val_accuracy: 0.9092 - val_loss: 0.2514\n",
      "Epoch 53/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9530 - loss: 0.1360 - val_accuracy: 0.9103 - val_loss: 0.2424\n",
      "Epoch 54/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9530 - loss: 0.1308 - val_accuracy: 0.9103 - val_loss: 0.2460\n",
      "Epoch 55/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9527 - loss: 0.1405 - val_accuracy: 0.9092 - val_loss: 0.2421\n",
      "Epoch 56/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9606 - loss: 0.1173 - val_accuracy: 0.9156 - val_loss: 0.2403\n",
      "Epoch 57/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9559 - loss: 0.1300 - val_accuracy: 0.9124 - val_loss: 0.2386\n",
      "Epoch 58/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9632 - loss: 0.1147 - val_accuracy: 0.9156 - val_loss: 0.2423\n",
      "Epoch 59/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9644 - loss: 0.1088 - val_accuracy: 0.9124 - val_loss: 0.2473\n",
      "Epoch 60/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9572 - loss: 0.1143 - val_accuracy: 0.9145 - val_loss: 0.2398\n",
      "Epoch 61/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9615 - loss: 0.1109 - val_accuracy: 0.9071 - val_loss: 0.2434\n",
      "Epoch 62/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9643 - loss: 0.1012 - val_accuracy: 0.9156 - val_loss: 0.2445\n",
      "Examining case:  1 3 100 0.1 sigmoid 0.0001\n",
      "Epoch 1/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.0495 - loss: 4.2375 - val_accuracy: 0.1335 - val_loss: 3.8498\n",
      "Epoch 2/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.1490 - loss: 3.7675 - val_accuracy: 0.1335 - val_loss: 3.6081\n",
      "Epoch 3/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.1468 - loss: 3.5729 - val_accuracy: 0.1335 - val_loss: 3.4962\n",
      "Epoch 4/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1622 - loss: 3.4587 - val_accuracy: 0.1335 - val_loss: 3.4299\n",
      "Epoch 5/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1701 - loss: 3.4034 - val_accuracy: 0.1335 - val_loss: 3.3738\n",
      "Examining case:  2 3 200 0.1 relu 0.0001\n",
      "Epoch 1/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.0876 - loss: 5.0633 - val_accuracy: 0.5011 - val_loss: 2.3744\n",
      "Epoch 2/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.4689 - loss: 2.3751 - val_accuracy: 0.6763 - val_loss: 1.5150\n",
      "Epoch 3/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6409 - loss: 1.6386 - val_accuracy: 0.7404 - val_loss: 1.0915\n",
      "Epoch 4/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7193 - loss: 1.2011 - val_accuracy: 0.7831 - val_loss: 0.8536\n",
      "Epoch 5/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7685 - loss: 0.9352 - val_accuracy: 0.8152 - val_loss: 0.7052\n",
      "Examining case:  3 3 200 0.1 sigmoid 0.0001\n",
      "Epoch 1/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.0910 - loss: 4.1012 - val_accuracy: 0.1635 - val_loss: 3.5653\n",
      "Epoch 2/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1742 - loss: 3.5386 - val_accuracy: 0.1335 - val_loss: 3.4092\n",
      "Epoch 3/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1941 - loss: 3.3534 - val_accuracy: 0.2126 - val_loss: 3.2895\n",
      "Epoch 4/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2341 - loss: 3.2773 - val_accuracy: 0.2628 - val_loss: 3.1353\n",
      "Epoch 5/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2983 - loss: 3.1101 - val_accuracy: 0.3280 - val_loss: 2.9434\n",
      "Examining case:  4 3 300 0.1 relu 0.0001\n",
      "Epoch 1/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.2061 - loss: 4.0052 - val_accuracy: 0.6774 - val_loss: 1.6074\n",
      "Epoch 2/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6439 - loss: 1.6788 - val_accuracy: 0.7532 - val_loss: 1.0068\n",
      "Epoch 3/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7337 - loss: 1.1158 - val_accuracy: 0.8109 - val_loss: 0.7130\n",
      "Epoch 4/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8038 - loss: 0.7806 - val_accuracy: 0.8440 - val_loss: 0.5413\n",
      "Epoch 5/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8368 - loss: 0.5904 - val_accuracy: 0.8536 - val_loss: 0.4514\n",
      "Examining case:  5 3 300 0.1 sigmoid 0.0001\n",
      "Epoch 1/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.0846 - loss: 3.9678 - val_accuracy: 0.1335 - val_loss: 3.4405\n",
      "Epoch 2/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1699 - loss: 3.3793 - val_accuracy: 0.1966 - val_loss: 3.2413\n",
      "Epoch 3/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2352 - loss: 3.1773 - val_accuracy: 0.2906 - val_loss: 2.9886\n",
      "Epoch 4/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3038 - loss: 2.9280 - val_accuracy: 0.3697 - val_loss: 2.7306\n",
      "Epoch 5/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3813 - loss: 2.6934 - val_accuracy: 0.4188 - val_loss: 2.4949\n",
      "Examining case:  6 6 100 0.1 relu 0.0001\n",
      "Epoch 1/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.0535 - loss: 4.3559 - val_accuracy: 0.2158 - val_loss: 3.6589\n",
      "Epoch 2/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2057 - loss: 3.5676 - val_accuracy: 0.3504 - val_loss: 2.8597\n",
      "Epoch 3/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2892 - loss: 3.0187 - val_accuracy: 0.4573 - val_loss: 2.3724\n",
      "Epoch 4/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3909 - loss: 2.5324 - val_accuracy: 0.5684 - val_loss: 1.9701\n",
      "Epoch 5/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4699 - loss: 2.2901 - val_accuracy: 0.6197 - val_loss: 1.6724\n",
      "Examining case:  7 6 100 0.1 sigmoid 0.0001\n",
      "Epoch 1/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.0137 - loss: 4.2867 - val_accuracy: 0.1335 - val_loss: 3.8884\n",
      "Epoch 2/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1304 - loss: 3.8121 - val_accuracy: 0.1335 - val_loss: 3.6274\n",
      "Epoch 3/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1515 - loss: 3.6236 - val_accuracy: 0.1335 - val_loss: 3.5458\n",
      "Epoch 4/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1462 - loss: 3.5599 - val_accuracy: 0.1335 - val_loss: 3.5225\n",
      "Epoch 5/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1440 - loss: 3.5366 - val_accuracy: 0.1335 - val_loss: 3.5149\n",
      "Examining case:  8 6 200 0.1 relu 0.0001\n",
      "Epoch 1/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.0867 - loss: 4.2004 - val_accuracy: 0.4177 - val_loss: 2.6757\n",
      "Epoch 2/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4071 - loss: 2.6785 - val_accuracy: 0.6357 - val_loss: 1.7132\n",
      "Epoch 3/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5781 - loss: 1.8864 - val_accuracy: 0.7094 - val_loss: 1.2399\n",
      "Epoch 4/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6514 - loss: 1.4574 - val_accuracy: 0.7415 - val_loss: 1.0122\n",
      "Epoch 5/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7063 - loss: 1.1737 - val_accuracy: 0.7746 - val_loss: 0.8410\n",
      "Examining case:  9 6 200 0.1 sigmoid 0.0001\n",
      "Epoch 1/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.0440 - loss: 4.0927 - val_accuracy: 0.1335 - val_loss: 3.5854\n",
      "Epoch 2/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1493 - loss: 3.5489 - val_accuracy: 0.1335 - val_loss: 3.5237\n",
      "Epoch 3/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1428 - loss: 3.5471 - val_accuracy: 0.1335 - val_loss: 3.5109\n",
      "Epoch 4/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.1474 - loss: 3.5060 - val_accuracy: 0.1335 - val_loss: 3.5023\n",
      "Epoch 5/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.1556 - loss: 3.5110 - val_accuracy: 0.1335 - val_loss: 3.4567\n",
      "Examining case:  10 6 300 0.1 relu 0.0001\n",
      "Epoch 1/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.1466 - loss: 3.8416 - val_accuracy: 0.5994 - val_loss: 1.9663\n",
      "Epoch 2/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5670 - loss: 1.9648 - val_accuracy: 0.7222 - val_loss: 1.1520\n",
      "Epoch 3/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6938 - loss: 1.3024 - val_accuracy: 0.7831 - val_loss: 0.8070\n",
      "Epoch 4/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7535 - loss: 0.9919 - val_accuracy: 0.8130 - val_loss: 0.6553\n",
      "Epoch 5/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7993 - loss: 0.7671 - val_accuracy: 0.8248 - val_loss: 0.5474\n",
      "Examining case:  11 6 300 0.1 sigmoid 0.0001\n",
      "Epoch 1/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.0700 - loss: 4.0507 - val_accuracy: 0.1335 - val_loss: 3.5444\n",
      "Epoch 2/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.1432 - loss: 3.5299 - val_accuracy: 0.1335 - val_loss: 3.5148\n",
      "Epoch 3/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.1371 - loss: 3.5278 - val_accuracy: 0.1335 - val_loss: 3.4929\n",
      "Epoch 4/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.1520 - loss: 3.4533 - val_accuracy: 0.2276 - val_loss: 3.3642\n",
      "Epoch 5/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.2223 - loss: 3.2686 - val_accuracy: 0.2276 - val_loss: 3.1184\n",
      "Examining case:  12 12 100 0.1 relu 0.0001\n",
      "Epoch 1/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.0468 - loss: 4.2508 - val_accuracy: 0.1335 - val_loss: 3.5669\n",
      "Epoch 2/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.1303 - loss: 3.5989 - val_accuracy: 0.1335 - val_loss: 3.1989\n",
      "Epoch 3/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.1467 - loss: 3.2885 - val_accuracy: 0.2286 - val_loss: 3.0035\n",
      "Epoch 4/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.1968 - loss: 3.1242 - val_accuracy: 0.2511 - val_loss: 2.7908\n",
      "Epoch 5/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.2427 - loss: 2.9151 - val_accuracy: 0.3226 - val_loss: 2.5978\n",
      "Examining case:  13 12 100 0.1 sigmoid 0.0001\n",
      "Epoch 1/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step - accuracy: 0.0301 - loss: 4.3484 - val_accuracy: 0.0951 - val_loss: 3.9428\n",
      "Epoch 2/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.0733 - loss: 3.9020 - val_accuracy: 0.0951 - val_loss: 3.6707\n",
      "Epoch 3/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.0950 - loss: 3.6637 - val_accuracy: 0.1335 - val_loss: 3.5667\n",
      "Epoch 4/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.1227 - loss: 3.6215 - val_accuracy: 0.1335 - val_loss: 3.5368\n",
      "Epoch 5/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.1364 - loss: 3.5743 - val_accuracy: 0.1335 - val_loss: 3.5227\n",
      "Examining case:  14 12 200 0.1 relu 0.0001\n",
      "Epoch 1/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - accuracy: 0.0613 - loss: 4.1570 - val_accuracy: 0.1368 - val_loss: 3.2008\n",
      "Epoch 2/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.1756 - loss: 3.1727 - val_accuracy: 0.3323 - val_loss: 2.6425\n",
      "Epoch 3/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.2969 - loss: 2.7057 - val_accuracy: 0.3590 - val_loss: 2.2222\n",
      "Epoch 4/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.3849 - loss: 2.2668 - val_accuracy: 0.4647 - val_loss: 1.8892\n",
      "Epoch 5/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.4474 - loss: 2.0640 - val_accuracy: 0.5513 - val_loss: 1.6786\n",
      "Examining case:  15 12 200 0.1 sigmoid 0.0001\n",
      "Epoch 1/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 15ms/step - accuracy: 0.0230 - loss: 4.3343 - val_accuracy: 0.1335 - val_loss: 3.6458\n",
      "Epoch 2/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.1370 - loss: 3.6171 - val_accuracy: 0.1335 - val_loss: 3.5345\n",
      "Epoch 3/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.1319 - loss: 3.5617 - val_accuracy: 0.1335 - val_loss: 3.5239\n",
      "Epoch 4/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.1373 - loss: 3.5132 - val_accuracy: 0.1335 - val_loss: 3.5164\n",
      "Epoch 5/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.1382 - loss: 3.5687 - val_accuracy: 0.1335 - val_loss: 3.5135\n",
      "Examining case:  16 12 300 0.1 relu 0.0001\n",
      "Epoch 1/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - accuracy: 0.0894 - loss: 3.9766 - val_accuracy: 0.2393 - val_loss: 2.9311\n",
      "Epoch 2/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.2652 - loss: 2.8672 - val_accuracy: 0.4049 - val_loss: 2.1524\n",
      "Epoch 3/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.4226 - loss: 2.1753 - val_accuracy: 0.5801 - val_loss: 1.6061\n",
      "Epoch 4/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.5322 - loss: 1.7727 - val_accuracy: 0.6282 - val_loss: 1.3215\n",
      "Epoch 5/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.5921 - loss: 1.4772 - val_accuracy: 0.6560 - val_loss: 1.2051\n",
      "Examining case:  17 12 300 0.1 sigmoid 0.0001\n",
      "Epoch 1/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - accuracy: 0.0743 - loss: 4.0961 - val_accuracy: 0.1335 - val_loss: 3.5460\n",
      "Epoch 2/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.1266 - loss: 3.5523 - val_accuracy: 0.1335 - val_loss: 3.5167\n",
      "Epoch 3/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.1324 - loss: 3.5524 - val_accuracy: 0.1335 - val_loss: 3.5175\n",
      "Epoch 4/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.1437 - loss: 3.5094 - val_accuracy: 0.1335 - val_loss: 3.5157\n",
      "Epoch 5/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.1484 - loss: 3.5212 - val_accuracy: 0.1335 - val_loss: 3.5109\n",
      "Best model\n",
      "<Sequential name=sequential, built=True>\n"
     ]
    }
   ],
   "source": [
    "set_epochs = [ 100 ]\n",
    "set_layers = [ 3, 6, 12 ]\n",
    "set_neurons_per_layer = [100, 200, 300]\n",
    "set_drop_out = [ 0.1 ]\n",
    "set_activ = [\"relu\", \"sigmoid\"]\n",
    "set_learning_rate = [0.0001]\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=0)\n",
    "\n",
    "best_accuracy = None\n",
    "best_model = None\n",
    "best_history = None\n",
    "\n",
    "i = 0\n",
    "for epochs in set_epochs:\n",
    "    for layers in set_layers:\n",
    "        for neurons_per_layer in set_neurons_per_layer:\n",
    "            for drop_out in set_drop_out:\n",
    "                for f in set_activ:\n",
    "                    for lr in set_learning_rate:\n",
    "                        print(\"Examining case: \", i, layers, neurons_per_layer, drop_out, f, lr)\n",
    "                        model = CreateNeuralNetwork(genes, labels_count, layers, neurons_per_layer, drop_out, f, lr, False)\n",
    "\n",
    "                        history = model.fit(x_train, y_train, epochs=epochs, validation_data=(x_test, y_test), callbacks=callback)\n",
    "\n",
    "                        # train_accuracy = history.history['accuracy'][-1]\n",
    "                        val_accuracy = history.history['val_accuracy'][-1]\n",
    "\n",
    "                        if best_model == None or val_accuracy > best_accuracy:\n",
    "                            best_model = model\n",
    "                            best_accuracy = val_accuracy\n",
    "                            best_history = history\n",
    "\n",
    "                        i=i+1\n",
    "\n",
    "print(\"Best model\")\n",
    "print(best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the best model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9161 - loss: 0.2551\n",
      "0.24446527659893036\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = best_model.evaluate(x_test, y_test)\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save to disk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "best_model.save(\"../models/nn.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate precision & recall:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "   Astro L1-2 FGFR3 GFAP       1.00      1.00      1.00         3\n",
      "Astro L1-6 FGFR3 SLC14A1       1.00      1.00      1.00        11\n",
      "       Endo L2-6 NOSTRIN       0.00      0.00      0.00         0\n",
      "        Exc L2 LAMP5 LTK       0.83      0.91      0.87        47\n",
      "Exc L2-3 LINC00507 FREM3       0.94      0.93      0.94       125\n",
      "Exc L2-4 LINC00507 GLP2R       0.92      0.85      0.88        13\n",
      "   Exc L3-4 RORB CARM1P1       0.94      0.89      0.91        18\n",
      "   Exc L3-5 RORB COL22A1       0.90      0.90      0.90        10\n",
      "      Exc L3-5 RORB ESR1       0.99      1.00      0.99        89\n",
      "   Exc L3-5 RORB FILIP1L       0.82      0.82      0.82        17\n",
      "    Exc L3-5 RORB TWIST2       1.00      0.33      0.50         3\n",
      "    Exc L4-5 FEZF2 SCN4B       0.00      0.00      0.00         1\n",
      "     Exc L4-5 RORB DAPK2       1.00      0.85      0.92        13\n",
      "    Exc L4-5 RORB FOLH1B       1.00      0.92      0.96        60\n",
      "     Exc L4-6 FEZF2 IL26       1.00      1.00      1.00        23\n",
      "       Exc L4-6 RORB C1R       0.89      1.00      0.94         8\n",
      "    Exc L4-6 RORB SEMA3E       0.91      1.00      0.95        48\n",
      "      Exc L5-6 FEZF2 ABO       1.00      1.00      1.00        21\n",
      " Exc L5-6 FEZF2 EFTUD1P1       0.96      1.00      0.98        24\n",
      "     Exc L5-6 RORB TTC12       0.92      0.85      0.88        13\n",
      "   Exc L5-6 SLC17A7 IL15       1.00      1.00      1.00         1\n",
      "   Exc L5-6 THEMIS C1QL3       0.97      0.99      0.98        96\n",
      "  Exc L5-6 THEMIS CRABP1       0.83      0.83      0.83         6\n",
      " Exc L5-6 THEMIS DCSTAMP       0.00      0.00      0.00         1\n",
      "   Exc L5-6 THEMIS FGF10       0.80      0.67      0.73         6\n",
      "      Exc L6 FEZF2 OR2T8       0.00      0.00      0.00         0\n",
      "     Exc L6 FEZF2 SCUBE1       1.00      1.00      1.00         3\n",
      "       Inh L1 SST CHRNA4       0.33      0.25      0.29         4\n",
      "         Inh L1 SST NMBR       1.00      1.00      1.00        14\n",
      "      Inh L1-2 GAD1 MC4R       0.62      0.83      0.71         6\n",
      "      Inh L1-2 LAMP5 DBP       0.00      0.00      0.00         0\n",
      "     Inh L1-2 PAX6 CDH12       0.75      1.00      0.86         6\n",
      " Inh L1-2 PAX6 TNFAIP8L3       0.00      0.00      0.00         3\n",
      "      Inh L1-2 SST BAGE2       0.83      0.71      0.77         7\n",
      "        Inh L1-2 VIP LBH       0.75      0.75      0.75         4\n",
      "     Inh L1-2 VIP PCDH20       0.00      0.00      0.00         0\n",
      "    Inh L1-2 VIP TSPAN12       0.00      0.00      0.00         1\n",
      "      Inh L1-3 PAX6 SYT6       0.00      0.00      0.00         0\n",
      "      Inh L1-3 SST CALB1       0.89      1.00      0.94        16\n",
      "   Inh L1-3 VIP ADAMTSL1       0.75      1.00      0.86         3\n",
      "    Inh L1-3 VIP CCDC184       0.75      0.75      0.75         4\n",
      "      Inh L1-3 VIP CHRM2       0.85      0.85      0.85        13\n",
      "        Inh L1-3 VIP GGH       0.88      0.78      0.82         9\n",
      "     Inh L1-4 LAMP5 LCP2       1.00      1.00      1.00        20\n",
      "     Inh L1-4 VIP CHRNA6       0.00      0.00      0.00         0\n",
      "      Inh L1-4 VIP OPRM1       1.00      0.75      0.86         4\n",
      "       Inh L1-4 VIP PENK       0.00      0.00      0.00         0\n",
      "      Inh L2-3 VIP CASC6       0.50      0.33      0.40         3\n",
      "    Inh L2-4 PVALB WFDC2       0.77      1.00      0.87        17\n",
      "       Inh L2-4 SST FRZB       0.50      0.25      0.33         4\n",
      "      Inh L2-4 VIP CBLN1       0.75      1.00      0.86         3\n",
      "     Inh L2-4 VIP SPAG17       1.00      1.00      1.00         1\n",
      "   Inh L2-5 PVALB SCUBE3       0.00      0.00      0.00         1\n",
      "   Inh L2-5 VIP SERPINF1       1.00      0.50      0.67         2\n",
      "        Inh L2-5 VIP TYR       1.00      1.00      1.00         1\n",
      "      Inh L2-6 LAMP5 CA1       1.00      1.00      1.00        11\n",
      "       Inh L2-6 VIP QPCT       0.33      0.50      0.40         2\n",
      "     Inh L3-5 SST ADGRG6       0.88      0.88      0.88         8\n",
      "       Inh L3-6 SST HPGD       1.00      0.50      0.67         4\n",
      "        Inh L3-6 SST NPY       0.00      0.00      0.00         1\n",
      "   Inh L3-6 VIP HS3ST3A1       0.60      0.75      0.67         4\n",
      "     Inh L4-5 PVALB MEPE       1.00      0.60      0.75         5\n",
      "     Inh L4-5 SST STK32A       1.00      0.71      0.83         7\n",
      "    Inh L4-6 PVALB SULF1       0.73      0.80      0.76        10\n",
      "     Inh L4-6 SST B3GAT2       0.79      1.00      0.88        11\n",
      "     Inh L4-6 SST GXYLT2       0.43      1.00      0.60         3\n",
      "     Inh L5-6 GAD1 GLP1R       0.00      0.00      0.00         0\n",
      "     Inh L5-6 PVALB LGR5       0.71      1.00      0.83         5\n",
      "    Inh L5-6 SST KLHDC8A       1.00      1.00      1.00         3\n",
      "   Inh L5-6 SST MIR548F2       1.00      0.75      0.86         4\n",
      "    Inh L5-6 SST NPM1P10       1.00      0.60      0.75        10\n",
      "         Inh L5-6 SST TH       1.00      1.00      1.00         3\n",
      "       Micro L1-3 TYROBP       1.00      1.00      1.00         1\n",
      "         OPC L1-6 PDGFRA       1.00      1.00      1.00        20\n",
      "       Oligo L1-6 OPALIN       1.00      1.00      1.00        18\n",
      "\n",
      "               micro avg       0.92      0.92      0.92       936\n",
      "               macro avg       0.71      0.69      0.69       936\n",
      "            weighted avg       0.92      0.92      0.91       936\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maria\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\maria\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\maria\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\maria\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\maria\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\maria\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "predictions = np.argmax(best_model.predict(x_test), axis=-1)\n",
    "\n",
    "y_test_labels = np.argmax(y_test, axis=1) # One hot vextors to labels\n",
    "\n",
    "print(classification_report(y_test_labels, predictions, labels=np.arange(labels_count), target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.5)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = plt.figure().gca()\n",
    "plt.plot(best_history.history['loss'], label=\"Train Loss\")\n",
    "plt.plot(best_history.history['val_loss'], label=\"Val Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\" Loss\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.ylim(0, 1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">13,900</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">7,575</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m13,900\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m)             │         \u001b[38;5;34m7,575\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">125,027</span> (488.39 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m125,027\u001b[0m (488.39 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">41,675</span> (162.79 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m41,675\u001b[0m (162.79 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">83,352</span> (325.60 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m83,352\u001b[0m (325.60 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
